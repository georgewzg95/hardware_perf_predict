# Hardware Performance Prediction
This is a paper collection of performance prediction for hardware

## Cross-Platform performance prediction
1. Cross-architecture performance prediction (XAPP) using CPU code to predict GPU performance [[MICRO'15](https://dl.acm.org/doi/10.1145/2830772.2830780)]
2. Accurate phase-level cross-platform power and performance estimation [[DAC'16](http://slam.ece.utexas.edu/pubs/dac16.LACross.pdf)]
3. HALWPE: Hardware-Assisted Light Weight Performance Estimation for GPUs [[DAC'17](https://dl.acm.org/doi/10.1145/3061639.3062257)]

## Program Properties
1. Comparing Benchmarks Using Key Microarchitecture-Independent Characteristics [[IISWC'06](https://users.elis.ugent.be/~leeckhou/papers/iiswc06-hoste.pdf)]

## HLS
1. HLSPredict: Cross Platform Performance Prediction for FPGA High-Level Synthesis [[ICCAD'18](https://drive.google.com/file/d/1V9TmufJPI9mohLFng6NYh7PMjNGfqn6o/view?usp=sharing)]
2. Machine Learning Based Routing Congestion Prediction in FPGA High-Level Synthesis [[DATE'19](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8714724)]
3. fast and accurate estimation of quality of results in high-level synthesis with machine learning [[FCCM'18](https://www.csl.cornell.edu/~zhiruz/pdfs/hls-qor-fccm2018.pdf)]
4. Accurate operation delay prediction for FPGA HLS using graph neural networks [[ICCAD'20](https://www.csl.cornell.edu/~zhiruz/pdfs/dsp-gnn-iccad2020.pdf)]
5. A Graph Deep Learning Framework for High-Level Synthesis Design Space Exploration [[Arxiv](https://arxiv.org/pdf/2111.14767.pdf)]
6. ScaleHLS: A New Scalable High-Level Synthesis Framework on Multi-Level Intermediate Representation [[HPCA'22](https://arxiv.org/pdf/2111.14767.pdf)]
7. High-Level Synthesis Performance Prediction using GNNs: Benchmarking, Modeling, and Advancing [[arxiv](https://arxiv.org/abs/2201.06848)]
8. PowerGear: Early-Stage Power Estimation in FPGA HLS via Heterogeneous Edge-Centric GNNs [[DATE'22](https://arxiv.org/abs/2201.10114)]
9. HL-Pow: A Learning-Based Power Modeling Framework for High-Level Synthesis [[ASP-DAC'20](https://arxiv.org/abs/2009.00871)]
10. Accurate Operation Delay Prediction for FPGA HLS Using Graph Neural Networks [[ICCAD'20](https://www.csl.cornell.edu/~zhiruz/pdfs/dsp-gnn-iccad2020.pdf)]
11. Pyramid: Machine Learning Framework to Estimate the Optimal Timing and Resource Usage of a High-Level Synthesis Design [[FPL'19](https://drive.google.com/file/d/1qxLMsXGCWUi4kG9kyOALviH1Cgd-iXA1/view?usp=sharing)]

## RTL-level prediction task
1. Power Modeling on FPGA: A Neural Model for RT-Level Power Estimation [[Link](https://drive.google.com/file/d/10QPPFK522y1j_EtNjIhFwAUKYHClSXSS/view?usp=sharing)]
2. Dynamic Power Estimation Based on Switching Activity Propagation [[Link](https://drive.google.com/file/d/1y_B0g_Gul2FGeWGjvHx33rgRMYb_stPC/view?usp=sharing)]
3. SNSâ€™s not a Synthesizer: A Deep-Learning-Based Synthesis Predictor [[ISCA'22](https://drive.google.com/file/d/1ks8W4jWDXqYfUtxfLfj2ooNAQBcnVps_/view?usp=share_link)]
4. How Good Is Your Verilog RTL Code? A Quick Answer from Machine Learning [[ICCAD'22](https://drive.google.com/file/d/1N9oosLZlT6MZobi33jAyBBx6UoNOkA1K/view?usp=sharing)]

## Other Relevant Papers
1. Ithemal: Accurate, Portable and Fast Basic Block Throughput Estimation using Deep Neural Networks [[ICML'19](https://arxiv.org/abs/1808.07412)][[code](https://github.com/ithemal/Ithemal)]
2. GPGPU Performance and Power Estimation Using Machine Learning [[HPCA'15](http://users.ece.utexas.edu/~derek/Papers/HPCA2015_GPUPowerModel.pdf)]
3. APOLLO: An Automated Power Modeling Framework for Runtime Power Introspection in High-Volume Commercial Microprocessors [[MICRO'21](https://dl.acm.org/doi/pdf/10.1145/3466752.3480064)]
4. GRANNITE: Graph Neural Network Inference for Transferable Power Estimation [[DAC'20](https://research.nvidia.com/publication/2020-07_grannite-graph-neural-network-inference-transferable-power-estimation)]
5. Spector: An OpenCL FPGA Benchmark Suite [[FPT'16](https://drive.google.com/file/d/1gPVINlk0ycxSYUNWDm12RoffP_RGmL3R/view?usp=share_link)][[source](https:llgithub.comlKastnerRG/spector)]
6. MLSBench: A Benchmark Set for Machine Learning based FPGA HLS Design Flows [[LASCAS'22](https://drive.google.com/file/d/1qDstB8OdGOBsO-k_8Uq2QYC5Mi8pAguB/view?usp=share_link)][[source](https://zenodo.org/record/3406668#.Y_5IlXaZOUk)]
7. OpenABC-D: A Large-Scale Dataset For Machine Learning Guided Integrated Circuit Synthesis [[arxiv](https://drive.google.com/file/d/1x1ix-0ArOwRQgwCwHPuxskzBnGfI73HI/view?usp=share_link)][[source](https://github.com/nyu-mlda/openabc)]
8. CircuitNet: An Open-Source Dataset for Machine Learning Applications in Electronic Design Automation (EDA) [[arxiv](https://drive.google.com/file/d/1i1pj_4BD0ubWLto7TGUnrFxjD3GifAu0/view?usp=share_link)][[source](https://circuitnet.github.io/)]


## Survey
1. Machine Learning for Electronic Design Automation: A Survey [[Survey](https://dl.acm.org/doi/pdf/10.1145/3451179)]
2. High-Level Synthesis Hardware Design for FPGA-Based Accelerators: Models, Methodologies, and Frameworks[[Survey](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9864576)]



## Disertation
1. Performance and Power Prediction of Compute Accelerators Using Machine Learning [[Link](https://drive.google.com/file/d/1RDAIQrshKoAtCXVA_7LNMJEL0-MbwLKW/view?usp=sharing)]
2. Learning-based power modeling for FPGA : from design time to run time [[Link](https://lbezone.ust.hk/pdfviewer/web/viewer.php?file=aHR0cHM6Ly9sYmV6b25lLnVzdC5oay9vYmovMS9vLzk5MTAxMjc4NjI2OTQwMzQxMi85OTEwMTI3ODYyNjk0MDM0MTIucGRm#page=1)]
3. Performance, Power, and Confidence Modeling of Digital Designs [[Link](https://repositories.lib.utexas.edu/bitstream/handle/2152/31420/WU-DISSERTATION-2015.pdf?sequence=1&isAllowed=y)]
4. Learning-Based System-Level Power Modeling of Hardware IPs [[Link](https://repositories.lib.utexas.edu/bitstream/handle/2152/63013/LEE-DISSERTATION-2017.pdf?sequence=1)]
